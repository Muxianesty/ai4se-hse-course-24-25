{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка обработанного датасета с личного Google Drive."
      ],
      "metadata": {
        "id": "BSG5VOjSnv-d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cwKOCSsolSh4",
        "outputId": "e3a9c4c2-30f5-414e-95b0-745bb9b8882d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/prepared-data/cache-0bf1b118d60bcde3.arrow',\n",
              " '/content/prepared-data/cache-5e30699a7978c804.arrow',\n",
              " '/content/prepared-data/cache-6fa1062e4bd6a5e1.arrow',\n",
              " '/content/prepared-data/cache-7b4579fd319655b4.arrow',\n",
              " '/content/prepared-data/cache-8cffc1c9416249ea.arrow',\n",
              " '/content/prepared-data/cache-8ff8b28f0a40b846.arrow',\n",
              " '/content/prepared-data/cache-14b974e6761a1ee8.arrow',\n",
              " '/content/prepared-data/cache-20c9961dcb9aa7af.arrow',\n",
              " '/content/prepared-data/cache-21d8d0fffa7d3ef7.arrow',\n",
              " '/content/prepared-data/cache-38b420facd7b0911.arrow',\n",
              " '/content/prepared-data/cache-71ccfea339ebeda2.arrow',\n",
              " '/content/prepared-data/cache-84e7c6f4b3fd11cb.arrow',\n",
              " '/content/prepared-data/cache-157bb8a23015943f.arrow',\n",
              " '/content/prepared-data/cache-267e053652b84e01.arrow',\n",
              " '/content/prepared-data/cache-2364d3ceb9033ef0.arrow',\n",
              " '/content/prepared-data/cache-5197ae4d5164021a.arrow',\n",
              " '/content/prepared-data/cache-44294a79f8289f5b.arrow',\n",
              " '/content/prepared-data/cache-092542cc72b883c4.arrow',\n",
              " '/content/prepared-data/cache-947939cb32445434.arrow',\n",
              " '/content/prepared-data/cache-4573591cddbe7e91.arrow',\n",
              " '/content/prepared-data/cache-a6855afe87223c20.arrow',\n",
              " '/content/prepared-data/cache-ab56006afdaa44dc.arrow',\n",
              " '/content/prepared-data/cache-abed3d2956a8f16f.arrow',\n",
              " '/content/prepared-data/cache-bc203d0bd3affe4e.arrow',\n",
              " '/content/prepared-data/cache-bf65b4c96db4c422.arrow',\n",
              " '/content/prepared-data/cache-c3bf245b393aa20e.arrow',\n",
              " '/content/prepared-data/cache-c4e0b088f5ab4e74.arrow',\n",
              " '/content/prepared-data/cache-d8e443a58d62052b.arrow',\n",
              " '/content/prepared-data/cache-d235aa40dcbdb2f6.arrow',\n",
              " '/content/prepared-data/cache-deaa08c715b4f76c.arrow',\n",
              " '/content/prepared-data/cache-e1e938a5b809d6ae.arrow',\n",
              " '/content/prepared-data/cache-ed681c596ed67929.arrow',\n",
              " '/content/prepared-data/cache-f518f4e336295776.arrow',\n",
              " '/content/prepared-data/data-00000-of-00001.arrow',\n",
              " '/content/prepared-data/dataset_info.json',\n",
              " '/content/prepared-data/state.json']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import gdown\n",
        "url = \"https://drive.google.com/drive/folders/16xTuNcBlzLzxAXE25rYoKztghsdHKb--?usp=drive_link\"\n",
        "gdown.download_folder(url, quiet=True, use_cookies=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --extra-index-url=https://pypi.nvidia.com cudf-cu12==24.6.*\n",
        "\n",
        "!pip install wandb datasets==2.20.0 evaluate==0.4.2 numpy==1.26.4 scikit-learn==1.5.1 tqdm==4.66.4 transformers torch openpyxl accelerate>=0.26.0"
      ],
      "metadata": {
        "id": "f13oH2IpqJ5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a256c5-6a7e-460c-9f17-7bbc0b101d2e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-24.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: cudf-cu12==24.6.* in /usr/local/lib/python3.10/dist-packages (24.6.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (5.5.0)\n",
            "Requirement already satisfied: cuda-python<13.0a0,>=12.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (12.2.1)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (12.2.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (2024.5.0)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (0.60.0)\n",
            "Requirement already satisfied: numpy<2.0a0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (1.26.4)\n",
            "Requirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (0.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (24.1)\n",
            "Requirement already satisfied: pandas<2.2.3dev0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (2.2.2)\n",
            "Requirement already satisfied: pynvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (0.3.0)\n",
            "Requirement already satisfied: pyarrow<16.2.0a0,>=16.1.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (16.1.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (13.9.3)\n",
            "Requirement already satisfied: rmm-cu12==24.6.* in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (24.6.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.6.*) (4.12.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python<13.0a0,>=12.0->cudf-cu12==24.6.*) (3.0.11)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x>=12.0.0->cudf-cu12==24.6.*) (0.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->cudf-cu12==24.6.*) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.3dev0,>=2.0->cudf-cu12==24.6.*) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.3dev0,>=2.0->cudf-cu12==24.6.*) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.3dev0,>=2.0->cudf-cu12==24.6.*) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu12==24.6.*) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu12==24.6.*) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->cudf-cu12==24.6.*) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.3dev0,>=2.0->cudf-cu12==24.6.*) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import wandb\n",
        "\n",
        "wandb.init(anonymous='must')"
      ],
      "metadata": {
        "id": "3alrxsAromNf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "75de201c-1a5b-467e-e32f-26cc4d6b83dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241027_205803-8ti9xioy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anony-mouse-833503157782547112/uncategorized/runs/8ti9xioy?apiKey=34e56de1a38fb724e510d53d66955d216fcb9c0d' target=\"_blank\">morning-plant-1</a></strong> to <a href='https://wandb.ai/anony-mouse-833503157782547112/uncategorized?apiKey=34e56de1a38fb724e510d53d66955d216fcb9c0d' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/anony-mouse-833503157782547112/uncategorized?apiKey=34e56de1a38fb724e510d53d66955d216fcb9c0d' target=\"_blank\">https://wandb.ai/anony-mouse-833503157782547112/uncategorized?apiKey=34e56de1a38fb724e510d53d66955d216fcb9c0d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/anony-mouse-833503157782547112/uncategorized/runs/8ti9xioy?apiKey=34e56de1a38fb724e510d53d66955d216fcb9c0d' target=\"_blank\">https://wandb.ai/anony-mouse-833503157782547112/uncategorized/runs/8ti9xioy?apiKey=34e56de1a38fb724e510d53d66955d216fcb9c0d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Do NOT share these links with anyone. They can be used to claim your runs."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/anony-mouse-833503157782547112/uncategorized/runs/8ti9xioy?apiKey=34e56de1a38fb724e510d53d66955d216fcb9c0d?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7e5204c2f8e0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_SIZE_FRACTION = 0.1\n",
        "OUTPUT_DIR = Path(f'/content/bert-model')\n",
        "\n",
        "conf_matrix_metric = evaluate.load(\"confusion_matrix\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def classifier(dataset: datasets.Dataset):\n",
        "    # Load model directly\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/codebert-base\")\n",
        "    model = model.to(\"cuda:0\")\n",
        "\n",
        "    def tokenization_map(data):\n",
        "        return tokenizer(data[\"message\"], truncation=True, padding=True)\n",
        "    mapped_dataset = dataset.map(tokenization_map, batched=True)\n",
        "\n",
        "    mapped_dataset = mapped_dataset.rename_column(\"is_toxic\", \"labels\")\n",
        "    train_and_test = mapped_dataset.train_test_split(test_size=TEST_SIZE_FRACTION)\n",
        "\n",
        "    def compute_metrics(results):\n",
        "        y_pred, y = results\n",
        "        y_pred = y_pred.argmax(axis=1)\n",
        "        f1 = f1_metric.compute(predictions=y_pred, references=y, average='weighted')\n",
        "        conf_matrix = conf_matrix_metric.compute(predictions=y_pred, references=y)\n",
        "        return {'f1': f1['f1'], \"conf_matrix\": conf_matrix[\"confusion_matrix\"]}\n",
        "\n",
        "    options = TrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=1e-4,\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        remove_unused_columns=True,\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=options,\n",
        "        train_dataset=train_and_test[\"train\"],\n",
        "        eval_dataset=train_and_test[\"test\"],\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "    trainer.train()\n",
        "\n",
        "    stats = trainer.evaluate()\n",
        "    print(stats)"
      ],
      "metadata": {
        "id": "Fo-ZtB4Mnu37"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_PREP_DATASET_PATH = Path('/content/prepared-data')\n",
        "\n",
        "def load_dataset(path: Path) -> datasets.Dataset:\n",
        "    return datasets.load_from_disk(str(path))\n",
        "\n",
        "classifier(load_dataset(DEFAULT_PREP_DATASET_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "sWHcbZJPpbdt",
        "outputId": "8cc8eeb1-7056-45aa-f54f-ad5c84285a85"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='726' max='726' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [726/726 19:23, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Conf Matrix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.322000</td>\n",
              "      <td>0.236498</td>\n",
              "      <td>0.926356</td>\n",
              "      <td>[[1000   47]\n",
              " [  48  196]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[[1000   47]\n",
            " [  48  196]]\" of type <class 'numpy.ndarray'> for key \"eval/conf_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='81' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [81/81 00:39]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[[1000   47]\n",
            " [  48  196]]\" of type <class 'numpy.ndarray'> for key \"eval/conf_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.23649752140045166, 'eval_f1': 0.9263556445365877, 'eval_conf_matrix': array([[1000,   47],\n",
            "       [  48,  196]]), 'eval_runtime': 41.1379, 'eval_samples_per_second': 31.382, 'eval_steps_per_second': 1.969, 'epoch': 1.0}\n"
          ]
        }
      ]
    }
  ]
}